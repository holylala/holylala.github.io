[{"title":"RabbitMQ中的几种交换器","date":"2017-11-30T11:12:45.000Z","path":"2017/11/30/rabbitmq-msgtype/","text":"前言RabbitMQ会根据路由键将消息从交换器路由到队列,但它是如何处理投递到多个队列的情况的呢？协议中定义的不同类型交换器发挥了作用。最常用的一共有三种类型：direct,fanout和topic。 direct交换器direct交换器非常简单:如果路由键匹配的话,消息就被投递到对应的队列,请参考下图 服务器必须实现direct类型交换器，包含一个空白字符串名称的默认交换器。当声明一个队列时，它会自动绑定到默认交换器，并以队列名称作为路由键。当默认的direct交换器无法满足应用程序的需求时,你可以声明你自己的交换器。 fanout交换器 这种类型的交换器会将收到的消息广播到绑定的队列上。当发送一条消息到fanout交换器时,它会把消息投递给所有附加在此交换器上的队列。实现对单条消息做不同方式的处理。 topic交换器 这类交换器可以使得来自不同源头的消息能够到达同一个队列,它能基于多个规则或标准进行路由,是一种更为灵活的交换器。发送到topic型交换器的消息不能包含任意路由键——它必须是一串字符并且以圆点符号隔开。这些字符可以是任意的，但它们通常都会指定成链接的消息的某些功能。一些有效的路由键如：”stock.usd.nyse”, “nyse.vmw”, “quick.orange.rabbit”等，路由键可以包括任意多个字符，上限是255个字节长度。绑定键也必须使用类似的形式。topic型交换器的逻辑和direct型很相像——消息发送时会指定一个特别的路由键，并且会被路由到所有与绑定键相匹配的队列。不过对绑定键有两种特殊类型： ”*” 符号用来代替任意单词 ”#” 符号可以代替0个或多个单词 topic类型交换器灵活之处体现在： 当一个队列以”#”作为绑定键时，它将接收所有消息，而不管路由键如何，类似于fanout型交换器 当特殊字符”*”、”#”没有用到绑定时，topic型交换器就好比direct型交换器了","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"}]},{"title":"使用Redis+Lua实现分布式限流","date":"2017-07-01T15:14:40.000Z","path":"2017/07/01/redis-lua-distributed-limit/","text":"分布式限流分布式限流最关键的是要将限流服务做成原子化,而解决方案可以使用 Redis+Lua 或者 Nginx+Lua 技术实现,通过这两种技术可以实现高并发和高性能。本文使用 Redis+Lua 实现时间窗内某个接口的请求数限流，实现了该功能后可以改造为限流总并发/请求数和限制总资源数。 Redis+Lua实现脚本 12345678910local key = KEYS[1] #限流KEY（一秒一个）local limit = tonumber(ARGV[1]) #限流大小local current = tonumber(redis.call('get',key) or \"0\") #获取不到 默认为0if current + 1 &gt; limit then #如果超出限流大小 return 0else #请求数+1，并设置2秒过期 redis.call(\"INCRBY\",key,\"1\") redis.call(\"expire\",key,\"2\") return 1end Java中判断是否需要限流的代码1234567891011public static boolean distributedLimit() throws Exception &#123; //redis lua 脚本 String luaScript = Files.toString(new File(\"xxxxLimit.lua\")),Charset.defaultCharset()); //将当前时间戳取秒数（极端情况下机器时钟不准时会存在一些小问题) String key = \"ip:\" + System.currentTimeMillis()/1000; //限流大小 String limit = \"30\"; //执行脚本 return (Long)jedis.eval(luaScript,Lists.newArrayList(key),Lists.newArrayList(limit)) == 1;&#125;","tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"},{"name":"Lua","slug":"Lua","permalink":"http://yoursite.com/tags/Lua/"},{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/分布式/"}]},{"title":"Python数据分析:Kaggle案例之StarCraft II Replay Analysis","date":"2017-05-14T15:37:01.000Z","path":"2017/05/14/python-da-kagglepro-starwar/","text":"1.Project Detail 项目地址: &gt;&gt;&gt; 数据来源: 下载 starcraft.csv(This dataset is an aggregate of the screen-fixations from screen movements of StarCraft 2 replay files) , 共21列数据 Inspiration: 分析每个战队的APM(Action per minute)和HoursPerWeek(Hours spent playing per week) 2.Code Say 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181# coding:utf-8# main.py# 引入必要的库 pandas_tools:封装的工具import pandas as pdfrom pandas_tools import inspect_dataset, visualize_league_attributes,\\ visualize_league_attribute_stats, process_missing_datadataset_path = './dataset/starcraft.csv' ##指定需要分析数据文件路径def run_main(): \"\"\" 主函数 \"\"\" ## Step.0 加载数据 df_data = pd.read_csv(dataset_path) ## Step.1 查看数据 数据预览 inspect_dataset(df_data) ## Step.2 处理缺失数据 设置默认值 df_data = process_missing_data(df_data) ## Step.3.1 可视化战队属性，散点图 column_names = ['LeagueIndex', # 战队索引号 'HoursPerWeek', # 每周游戏时间 'Age', # 战队中玩家的年龄 'APM', # 操作速度(技术能力) 'WorkersMade' # 单位时间的建造数 ] visualize_league_attributes(df_data[column_names]) ## list 不连续索引 ## Step3.2 可视化战队属性统计值 visualize_league_attribute_stats(df_data[column_names], 'APM', savedata_path='./league_apm_stats.csv', savefig_path='./league_apm_stats.png',) visualize_league_attribute_stats(df_data[column_names], 'HoursPerWeek', savedata_path='./league_hrs_stats.csv', savefig_path='./league_hrs_stats.png',) # 运行入口if __name__ == '__main__': run_main()# ---------------------------------------------------------------------------------------------# pandas_tools.pyimport matplotlib.pyplot as pltimport pandas as pdimport matplotlib.patches as mpatchesdef inspect_dataset(df_data): \"\"\" 查看加载的数据基本信息 \"\"\" print '数据集基本信息：' print df_data.info() print '数据集有%i行，%i列' %(df_data.shape[0], df_data.shape[1]) print '数据预览:' print df_data.head()def process_missing_data(df_data): \"\"\" 处理缺失数据 \"\"\" if df_data.isnull().values.any(): # 存在缺失数据 df_data = df_data.fillna(0.) # 填充nan# df_data = df_data.dropna() # 过滤nan return df_data def visualize_league_attributes(df_data, save_fig = True): \"\"\" 可视化战队属性 \"\"\" # 创建figure 放四张图 fig = plt.figure(figsize=(15.0, 10.0)) ax1 = fig.add_subplot(2,2,1) ax2 = fig.add_subplot(2,2,2) ax3 = fig.add_subplot(2,2,3) ax4 = fig.add_subplot(2,2,4) # 解决matplotlib显示中文问题 plt.rcParams['font.sans-serif'] = ['SimHei'] #指定默认字体 plt.rcParams['axes.unicode_minus'] = False #解决保存图像是负号'-'显示为方块的问题 fig.suptitle(u'战队属性') #给图起个标题 # 画散点图 横轴战队 纵轴每周游戏时间 ax1.scatter(df_data['LeagueIndex'], df_data['HoursPerWeek']) ax1.set_xlabel(u'战队') ax1.set_ylabel(u'每周游戏时间') ax2.scatter(df_data['LeagueIndex'], df_data['Age']) ax2.set_xlabel(u'战队') ax2.set_ylabel(u'玩家年龄') ax3.scatter(df_data['LeagueIndex'], df_data['APM']) ax3.set_xlabel(u'战队') ax3.set_ylabel(u'APM') ax4.scatter(df_data['LeagueIndex'], df_data['WorkersMade']) ax4.set_xlabel(u'战队') ax4.set_ylabel(u'单位时间建造数') if save_fig: plt.savefig('./league_attributes.png') #数据存储 plt.show() def visualize_league_attribute_stats(df_data, attr_label, savedata_path = '', savefig_path = ''): \"\"\" 可视化战队属性统计值 1到8 战队数 \"\"\" league_idx_lst = range(1,9) # 统计最小值 最大值 和均值 stats_min = [] stats_max = [] stats_mean = [] for league_idx in league_idx_lst: # 处理每一个战队的数据 # 数据选取 loc 标签索引 df_data['LeagueIndex'] == league_idx 行索引,true or false 只取满足条件的数据 attr_label:列索引 filtered_data = df_data.loc[df_data['LeagueIndex'] == league_idx, attr_label] stats_min.append(filtered_data.min()) stats_max.append(filtered_data.max()) stats_mean.append(filtered_data.mean()) league_ser = pd.Series(league_idx_lst, name='LeagueIndex') # 把各战队编号list变成series stats_min_ser = pd.Series(stats_min, name='min') # 把各战队统计数据list变成series stats_max_ser = pd.Series(stats_max, name='max') stats_mean_ser = pd.Series(stats_mean, name='mean') #把Series拼装成DataFrame axis=1 指定轴方向 横向拼接 df_result = pd.concat([league_ser, stats_min_ser, stats_max_ser, stats_mean_ser], axis=1) #数据保存 if savedata_path != '': df_result.to_csv(savedata_path, index=None) # 统计值可视化 # 创建figure fig = plt.figure(figsize=(15.0, 10.0)) fig.add_subplot(1,1,1) # 解决matplotlib显示中文问题 plt.rcParams['font.sans-serif'] = ['SimHei'] #指定默认字体 plt.rcParams['axes.unicode_minus'] = False #解决保存图像是负号'-'显示为方块的问题 plt.plot(df_result['LeagueIndex'], df_result['mean'], color='b') plt.plot(df_result['LeagueIndex'], df_result['min'], color='g') plt.plot(df_result['LeagueIndex'], df_result['max'], color='r') plt.xlabel(u\"战队\") plt.ylabel(attr_label) plt.title(attr_label + u\"--Lqian\") #添加图例 blue_patch = mpatches.Patch(color='blue', label=u\"均值 \" + attr_label) green_patch = mpatches.Patch(color='green', label=u'最小值 '+ attr_label) red_patch = mpatches.Patch(color='red', label=u'最大值 '+ attr_label) plt.legend(handles=[blue_patch, green_patch, red_patch], loc=2) if savefig_path != '': plt.savefig(savefig_path) plt.show() 3.战队属性散点图 4.战队APM 5.战队每周游戏时间 6.结论孰能生巧，Skill comes of practice.","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"纯代码","slug":"纯代码","permalink":"http://yoursite.com/tags/纯代码/"},{"name":"kaggle","slug":"kaggle","permalink":"http://yoursite.com/tags/kaggle/"},{"name":"matplotlib","slug":"matplotlib","permalink":"http://yoursite.com/tags/matplotlib/"},{"name":"pandas","slug":"pandas","permalink":"http://yoursite.com/tags/pandas/"}]},{"title":"走进Docker之Docker初识","date":"2017-04-30T17:34:03.000Z","path":"2017/05/01/docker-whatis/","text":"Docker历史 2010 dotCloud PAAS 2013 docker开源 2015.4 D轮 2014.6 Docker 1.0 2014.7 C轮 Now:free Community Edition (CE) and as a subscription in Enterprise Edition (EE) What’s Docker Docker is the world’s leading software container platform 开源 , 跨平台 技术核心 镜像： 集装箱 仓库 ： 码头 容器 ： 运行程序的地方 简单理解就是去仓库把镜像下到本地，用命令把镜像运行起来变成容器。 Docker仓库 官方库: &gt;&gt;&gt; 网 易: &gt;&gt;&gt;","tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Python数据分析:Kaggle案例之2016 Election Pools","date":"2017-04-30T15:58:01.000Z","path":"2017/04/30/python-da-kagglepro-elepolls/","text":"1.Project Detail 地址: &gt;&gt;&gt;(建议翻墙) 数据来源: 下载 presidential_polls.csv(This dataset is a collection of state and national polls conducted from November 2015-November 2016 on the 2016 presidential election) , 共27列数据 Inspiration: 分析每个月的民意调查统计趋势 2.撸代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164# coding:utf-8# 引入必要的库import numpy as npimport datetimeimport matplotlib.pyplot as plt# 判断一个字符串能否转换为floatdef is_convert_float(s): try: float(s) except: return False return Truedef get_sum(str_array): \"\"\" 返回字符串数组中数字的总和 \"\"\" # 去掉不能转换成数字的数据 cleaned_data = filter(is_convert_float, str_array) # 转换数据类型 float_array = np.array(cleaned_data, np.float) return np.sum(float_array)def run_main(): \"\"\" main function \"\"\" # 数据文件地址 filename = './presidential_polls.csv' ## Step1. 列名预处理 # 读取列名，即第一行数据 r:代表读取 f：代表打开的文件 with open(filename, 'r') as f: col_names_str = f.readline()[:-1] # [:-1]表示不读取末尾的换行符'\\n' 读取标题行 cycle,branch,... # 将字符串拆分，并组成列表 col_name_lst = col_names_str.split(',') # 使用的列名： 统计截止时间,克林顿民意数据,川普民意数据,克林顿校准民意数据,川普校准民意数据 use_col_name_lst = ['enddate', 'rawpoll_clinton', 'rawpoll_trump','adjpoll_clinton', 'adjpoll_trump'] # 获取相应列名的索引号 use_col_index_lst = [col_name_lst.index(use_col_name) for use_col_name in use_col_name_lst] ## Step2. 读取数据 data_array = np.loadtxt(filename, # 文件名 delimiter=',', # 分隔符 skiprows=1, # 跳过第一行，即跳过列名 dtype=str, # 数据类型 usecols=use_col_index_lst) # 指定读取的列索引号 ## Step3. 数据处理 # 处理日期格式数据 enddate_idx = use_col_name_lst.index('enddate') enddate_lst = data_array[:,enddate_idx].tolist() #拿到多维数组中某一列的数据 并转换成列表 # 将日期字符串格式统一，即'yy/dd/mm' enddate_lst = [enddate.replace('-', '/') for enddate in enddate_lst] # 将日期字符串转换成日期 date_lst = [datetime.datetime.strptime(enddate, '%m/%d/%Y') for enddate in enddate_lst] print data_array[:20] # ['10/30/2016' '45' '46' '43.29659' '44.72984'] # 构造年份-月份 字符列表 month_lst = ['%d-%02d' %(date_obj.year, date_obj.month) for date_obj in date_lst] month_array = np.array(month_lst) months = np.unique(month_array) #去掉重复的年 月 ## Step4. 数据分析 # 统计民意投票数 # 克林顿 # 原始数据 rawpoll 拿到指定列的全部数据 rawpoll_clinton_idx = use_col_name_lst.index('rawpoll_clinton') rawpoll_clinton_data = data_array[:, rawpoll_clinton_idx] # 调整后的数据 adjpool adjpoll_clinton_idx = use_col_name_lst.index('adjpoll_clinton') adjpoll_clinton_data = data_array[:, adjpoll_clinton_idx] # 川普 # 原始数据 rawpoll rawpoll_trump_idx = use_col_name_lst.index('rawpoll_trump') rawpoll_trump_data = data_array[:, rawpoll_trump_idx] # 调整后的数据 adjpoll adjpoll_trump_idx = use_col_name_lst.index('adjpoll_trump') adjpoll_trump_data = data_array[:, adjpoll_trump_idx] # 结果保存 results = [] #遍历唯一的年月 for month in months: # clinton # 原始数据 rawpoll rawpoll_clinton_month_data = rawpoll_clinton_data[month_array == month] # 统计当月的总票数 rawpoll_clinton_month_sum = get_sum(rawpoll_clinton_month_data) # 调整数据 adjpoll adjpoll_clinton_month_data = adjpoll_clinton_data[month_array == month] # 统计当月的总票数 adjpoll_clinton_month_sum = get_sum(adjpoll_clinton_month_data) # trump # 原始数据 rawpoll rawpoll_trump_month_data = rawpoll_trump_data[month_array == month] # 统计当月的总票数 rawpoll_trump_month_sum = get_sum(rawpoll_trump_month_data) # 调整数据 adjpoll adjpoll_trump_month_data = adjpoll_trump_data[month_array == month] # 统计当月的总票数 adjpoll_trump_month_sum = get_sum(adjpoll_trump_month_data) results.append((month, rawpoll_clinton_month_sum, adjpoll_clinton_month_sum, rawpoll_trump_month_sum, adjpoll_trump_month_sum)) print results months, raw_cliton_sum, adj_cliton_sum, raw_trump_sum, adj_trump_sum = zip(*results) ## Step5. 可视化分析结果 fig, subplot_arr = plt.subplots(2,2, figsize=(15,10)) # 原始数据趋势展示 subplot_arr[0,0].plot(raw_cliton_sum, color='r') subplot_arr[0,0].plot(raw_trump_sum, color='g') width = 0.25 x = np.arange(len(months)) subplot_arr[0,1].bar(x, raw_cliton_sum, width, color='r') subplot_arr[0,1].bar(x + width, raw_trump_sum, width, color='g') subplot_arr[0,1].set_xticks(x + width) subplot_arr[0,1].set_xticklabels(months, rotation='vertical') # 调整数据趋势展示 subplot_arr[1,0].plot(adj_cliton_sum, color='r') subplot_arr[1,0].plot(adj_trump_sum, color='g') width = 0.25 x = np.arange(len(months)) subplot_arr[1,1].bar(x, adj_cliton_sum, width, color='r') subplot_arr[1,1].bar(x + width, adj_trump_sum, width, color='g') subplot_arr[1,1].set_xticks(x + width) subplot_arr[1,1].set_xticklabels(months, rotation='vertical') plt.subplots_adjust(wspace=0.2) plt.show()# 运行入口if __name__ == '__main__': run_main() 3.数据分析结果(红色克林顿绿色川普) 4.结论一切都是命中注定，He says that everything is predetermined.","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"纯代码","slug":"纯代码","permalink":"http://yoursite.com/tags/纯代码/"},{"name":"kaggle","slug":"kaggle","permalink":"http://yoursite.com/tags/kaggle/"},{"name":"numpy","slug":"numpy","permalink":"http://yoursite.com/tags/numpy/"},{"name":"matplotlib","slug":"matplotlib","permalink":"http://yoursite.com/tags/matplotlib/"}]},{"title":"搭建Python开发环境(win10)","date":"2017-04-29T10:44:31.000Z","path":"2017/04/29/build-python-devenv/","text":"安装Anaconda2 版本: 4.3.1-Windows-x86_64 (选择Python3.6 or Python2.7) 安装地址: &gt;&gt; 安装 JetBrains PyCharm 版本: PyCharm Professional Edition 安装地址: &gt;&gt;, 安装时选择自动配置Python环境变量 PyCharm设置 在New Project的Interpreter中指定python.exe路径 Anaconda常用命令12345678python --vesion ipython #交互式命令行 Shell jupyter notebook #cd到.ipynb文件目录 启动jupyterexit 让Python带你飞","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"在redis中使用Lua脚本","date":"2017-04-28T15:40:21.000Z","path":"2017/04/28/redis-uselua/","text":"脚本介绍Redis在2.6版本中推出了脚本功能,使用Lua语言(一种“卫星语言”,能够方便地嵌入到其他语言中使用)编写脚本传到Redis中执行。在Lua脚本中可以调用大部分的Redis命令,使用脚本的好处如下: 减少网络开销: 多个redis请求可以在一个脚本中一次发送一个请求,减少网络往返时延。 原子操作: Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。编写脚本的过程中无需担心会出现竞态条件,也就无需使用事务。事务可以完成的所有功能都可以用脚本实现。 复用: 客户端发送的脚本会永久存储在Redis中,其他语言开发的项目可以复用之。 代码示例1.访问频率限制123456789101112131415161718local times = redis.call('incr',KEYS[1])if times == 1 then #KEYS[1]键刚创建,所以为其设置生存时间redis.call('expire',KEYS[1],ARGV[1])end if times &gt; tonumber(ARGV[2]) then return 0end return 1 #保存该脚本为test.lua,执行该脚本:redis-cli --eval /path/test.lua key1 , 10 2#--eval参数是告诉redis-cli读取并运行后面的Lua脚本,/path/test.jua是脚本文件的路径,key1是要操作的键，在脚本中使用KEYS[1]获取,10和2是参数，在脚本中使用ARGV[1]和ARGV[2]获得值（每10秒最多访问3次),注意空格 2.java代码示例123456789101112131415//redis lua 脚本static String luaScript = \"local timeValue = redis.call('get',KEYS[1]) if timeValue &lt; ARGV[1] then return redis.call('mset',KEYS[1],ARGV[1],KEYS[2],ARGV[2]) end return nil\";//执行脚本redisClient.executeLuaScript(luaScript,\"key1\", \"key2\", \"value1\", \"value2\");//executeLuaScript方法:public Object executeLuaScript(String script,String key1,String key2,String avg1,String avg2) throws Exception &#123; return this.execution(new JedisResultTask() &#123; protected Object doExecution(Jedis jedis) &#123; return jedis.eval(script,2,key1,key2,avg1,avg2); &#125; &#125;); &#125; 3.解决抢红包高并发的问题 传送门","tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"},{"name":"Lua","slug":"Lua","permalink":"http://yoursite.com/tags/Lua/"}]},{"title":"在Redis中使用管道","date":"2017-04-23T11:12:45.000Z","path":"2017/04/23/redis-usepip/","text":"使用场景客户端和Redis使用TCP协议连接。不论是客户端向Redis发送命令还是Redis向客户端返回命令的执行结果,都需要进过网络传输,这两部分的总耗时称为往返时延。大致来说到本地回环地址(loop back address)的往返时延在数据量级上相当于Redis处理一条简单命令的时间。如果执行较多的命令,每个命令的往返时延累加起来对性能还是有一定影响的。 在执行多个命令时每条命令都需要等待上一条命令执行完才能执行,即使命令不需要上一条命令的执行结果。Redis的底层通信协议对管道(pipelining)提供了支持。通过管道可以一次性发送多条命令并在执行完成后一次性将结果返回，当一组命令中每条命令都不依赖于之前命令的执行结果时就可以将这组命令一起通过管道发出。管道通过减少客户端与Redis的通信次数来实现降低往返时延累计值的目的。 简单概括两点就是: 多个命令之间没有依赖关系,每个命令只需单独执行 对响应时间要求苛刻 不使用管道时命令执行示意图（纵向表示时间） 使用管道时命令执行示意图 java代码示例1234567891011121314redisClient.executionPipelinedExt(new Redis.JedisResultTask&lt;Object&gt;() &#123; @Override protected Object doExecution(Jedis jedis) &#123; Pipeline pipeline = jedis.pipelined(); pipeline.set(“key1”,“value1”); pipeline.set(“key2”,“value2”); pipeline.set(“key3”,“value3”); ... pipeline.sync(); return null; &#125; &#125;); Python代码示例(使用redis-py) 12345678910111213141516171819import redisr = redis.StrictRedis()# redis-py的事务使用方式如下:pipe = r.pipeline()pipe.set('key1','value1')pipe.get('key1')result = pipe.execute()print result# 管道的使用方式和事务相同,只不过需要在创建时加上参数transaction=False:pipe = r.pipeline(transaction=False)# 支持链式调用r.pipeline().set('key1','value1').get('key1').execute()","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"},{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"HEXO+Github,搭建个性化博客","date":"2017-04-08T14:05:00.155Z","path":"2017/04/08/create-blog-by-hexo/","text":"本教程在Win10上完成的示例,Mac环境可同时参考&gt;&gt;&gt;&gt; 一.环境准备安装 Node.js1下载地址 https://nodejs.org/en/ 安装 Git1Git-1.9.5-preview20150319.exe 配置Git环境变量：123Path:..\\Git\\bin..\\Git\\libexec\\git-core 注册Github账户二.安装Hexo123456&gt; 打开 Node.js command prompt 控制台 (以管理员身份运行）&gt; 执行命令 npm install -g hexo&gt; 创建一个文件夹，如：C:\\blog，cd到blog里执行 : hexo init&gt; 继续再Blog目录下执行命令: hexo generate （hexo g 也可以），生成静态页面&gt; 启动本地服务，进行文章预览调试 : hexo server&gt; 浏览器输入 http://localhost:4000/ 三.配置Github1创建库,库名格式: 用户名.github.io 四.配置部署123456789&gt;在blog目录, 修改 _config.yml文件配置（修改后另存为UTF-8编码）:deploy: type: git repository: https://github.com/XXX/XXX.github.io.git branch: master&gt; 组件安装 ： npm install hexo-deployer-git --save &gt; 部署 hexo deploy 五.访问1https://XXX.github.io/ 六. 一些基本路径1文章在 source/_posts，编辑器可以用 Sublime，支持 markdown 语法。如果想修改头像可以直接在主题的 _config.yml 文件里面修改，友情链接，之类的都在这里 七.常用命令1234567hexo new \"postName\" #新建文章，生成指定名称的文章至 hexo\\source\\_posts\\postName.md 编辑器可以用Sublime，支持 markdown 语法 推荐一款markdown在线编辑工具(https://www.zybuluo.com/mdeditor),本机操作可使用markdownpad hexo new page \"pageName\" #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口 ,进行文章预览调试（http://localhost:4000/ ，'ctrl + c'关闭server）hexo deploy #将.deploy目录部署到GitHubhexo help #查看帮助hexo version #查看Hexo的版本 新增文章 修改文章后 依次执行以下命令123hexo clean #非必须hexo generatehexo deploy 八.更换主题主题下载：1234git clone https://github.com/litten/hexo-theme-yilia.git themes/yiliahttps://github.com/litten/hexo-theme-yilia.git 是主题路径themes/yilia 是主题目录 ,目录是否是yilia 无所谓，只要与_config.yml文件中的配置一致即可。 主题很多可自行选择。 主题配置修改123安装完成后，打开 blog\\_config.yml ，修改主题为 yiliatheme: yilia 主题配置项修改1打开 blog\\themes\\yilia 目录，编辑主题配置文件 _config.yml 更新主题12cd themes/yiliagit pull 九.域名绑定可参考这个&gt;&gt;&gt;","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]}]